{
 "metadata": {
  "name": "",
  "signature": "sha256:aecd1dc2eee72444943e63f1a69efb3e8220daf3c8bcbc7595dded55d34453f6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "%pylab inline\n",
      "from mpltools import style\n",
      "style.use('ggplot')\n",
      "pylab.rcParams['figure.figsize'] = 16, 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "import itertools\n",
      "import multiprocessing\n",
      "\n",
      "class SimpleMapReduce(object):\n",
      "    def __init__(self, map_func, reduce_func, num_workers=None):\n",
      "        self.map_func = map_func\n",
      "        self.reduce_func = reduce_func\n",
      "        self.pool = multiprocessing.Pool(num_workers)\n",
      "        \n",
      "    def partition(self, mapped_values):\n",
      "        partitioned_data = collections.defaultdict(list)\n",
      "        for key, value in mapped_values:\n",
      "            partitioned_data[key].append(value)\n",
      "        return partitioned_data.items()\n",
      "    \n",
      "    def __call__(self, inputs, chunksize=1):\n",
      "        map_responses = self.pool.map(self.map_func, inputs, chunksize=chunksize)\n",
      "        partitioned_data = self.partition(itertools.chain(*map_responses))\n",
      "        reduced_values = self.pool.map(self.reduce_func, partitioned_data)\n",
      "        return reduced_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "\n",
      "def file_to_words(filename):\n",
      "    STOP_WORDS = set(['arnab', 'rahul', 'that', 'have', 'this', 'what', 'there', 'want', 'with', 'dont', 'into', \\\n",
      "                      'your', 'yours', 'about', 'them', 'here','should','when', 'take','said','they', 'would', \\\n",
      "                      'because','about','been','them', 'were', 'think', 'like', 'from', 'there','done','which','make', \\\n",
      "                      'then', 'going', 'need', 'just', 'view', 'look', 'things', 'these', 'where', 'much', 'being', \\\n",
      "                      'thing', 'does', 'give', 'back', 'bring', 'doing', 'feel', 'more', 'give', 'case', 'asking', \\\n",
      "                      'some', 'taking', 'needs', 'says', 'modi', 'narendra', 'goswami', 'will', 'gandhi'])\n",
      "    \n",
      "    TR = string.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
      "#    print multiprocessing.current_process().name, 'reading', filename\n",
      "    output = []\n",
      "    \n",
      "    with open(filename, 'rt') as f:\n",
      "        for line in f:\n",
      "            line = line.translate(TR) # strip punctuation\n",
      "            for word in line.split():\n",
      "                word = word.lower()\n",
      "                if word.isalpha() and len(word) > 3 and word not in STOP_WORDS:\n",
      "                    output.append( (word, 1))\n",
      "        f.close()\n",
      "        return output\n",
      "    \n",
      "def count_words(item):\n",
      "    word, occurances = item\n",
      "    return (word, sum(occurances))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "\n",
      "def word_counts(input_files):\n",
      "    mapper = SimpleMapReduce(file_to_words, count_words)\n",
      "    word_counts = mapper(input_files)\n",
      "    word_counts.sort(key=operator.itemgetter(1))\n",
      "    word_counts.reverse()\n",
      "    return word_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modi = pd.DataFrame(word_counts(['data/modi.txt']), columns=['word', 'count'])\n",
      "rahul = pd.DataFrame(word_counts(['data/rahul.txt']), columns=['word', 'count'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "common_text = pd.merge(modi, rahul, on='word', suffixes=['_modi', '_rahul'], how='inner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "greater_10 = common_text[(common_text.count_modi > 10) & (common_text.count_rahul > 10)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "greater_10.plot(x=greater_10.word, kind='bar')\n",
      "plt.xlabel('Words')\n",
      "plt.ylabel('Word Count')\n",
      "plt.title('Word count of Modi Vs Rahul')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}